{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76dfd68f",
   "metadata": {},
   "source": [
    "### Use torchani interface to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5dd668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchani\n",
    "import os\n",
    "import math\n",
    "import torch.utils.tensorboard\n",
    "import tqdm\n",
    "\n",
    "# helper function to convert energy unit from Hartree to kcal/mol\n",
    "from torchani.units import hartree2kcalmol\n",
    "\n",
    "# device to run the training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce407ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcr = 5.2000e+00\n",
    "Rca = 3.5000e+00\n",
    "EtaR = torch.tensor([1.6000000e+01], device=device)\n",
    "ShfR = torch.tensor([0.3625, 0.63125, 9.0000000e-01, 1.1687500e+00, 1.4375000e+00, 1.7062500e+00, 1.9750000e+00, 2.2437500e+00, 2.5125000e+00, 2.7812500e+00, 3.0500000e+00, 3.3187500e+00, 3.5875000e+00, 3.8562500e+00, 4.1250000e+00, 4.3937500e+00, 4.6625000e+00, 4.9312500e+00], device=device)\n",
    "Zeta = torch.tensor([3.2000000e+01], device=device)\n",
    "ShfZ = torch.tensor([1.9634954e-01, 5.8904862e-01, 9.8174770e-01, 1.3744468e+00, 1.7671459e+00, 2.1598449e+00, 2.5525440e+00, 2.9452431e+00], device=device)\n",
    "EtaA = torch.tensor([8.0000000e+00], device=device)\n",
    "ShfA = torch.tensor([9.0000000e-01, 1.5500000e+00, 2.2000000e+00, 2.8500000e+00], device=device)\n",
    "species_order = ['H', 'C', 'N', 'O']\n",
    "num_species = len(species_order)\n",
    "aev_computer = torchani.AEVComputer(Rcr, Rca, EtaR, ShfR, EtaA, Zeta, ShfA, ShfZ, num_species)\n",
    "energy_shifter = torchani.utils.EnergyShifter(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b62a6c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self atomic energies:  tensor([-16.1395,  24.0818,  -8.0923, -44.0951], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    path = os.path.dirname(os.path.realpath(__file__))\n",
    "except NameError:\n",
    "    path = os.getcwd()\n",
    "dspath = os.path.join(path, './ani_gdb_s01.h5')\n",
    "batch_size = 2560\n",
    "\n",
    "training, validation = torchani.data.load(dspath).subtract_self_energies(energy_shifter, species_order).species_to_indices(species_order).shuffle().split(0.8, None)\n",
    "training = training.collate(batch_size).cache()\n",
    "validation = validation.collate(batch_size).cache()\n",
    "print('Self atomic energies: ', energy_shifter.self_energies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476244eb",
   "metadata": {},
   "source": [
    "When iterating the dataset, we will get a dict of name->property mapping\n",
    "\n",
    "##############################################################################\n",
    "\n",
    " Now let's define atomic neural networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e661a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aev_dim = aev_computer.aev_length\n",
    "\n",
    "H_network = torch.nn.Sequential(\n",
    "    torch.nn.Linear(aev_dim, 160),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(160, 128),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(128, 96),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(96, 1)\n",
    ")\n",
    "\n",
    "C_network = torch.nn.Sequential(\n",
    "    torch.nn.Linear(aev_dim, 144),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(144, 112),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(112, 96),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(96, 1)\n",
    ")\n",
    "\n",
    "N_network = torch.nn.Sequential(\n",
    "    torch.nn.Linear(aev_dim, 128),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(128, 112),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(112, 96),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(96, 1)\n",
    ")\n",
    "\n",
    "O_network = torch.nn.Sequential(\n",
    "    torch.nn.Linear(aev_dim, 128),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(128, 112),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(112, 96),\n",
    "    torch.nn.CELU(0.1),\n",
    "    torch.nn.Linear(96, 1)\n",
    ")\n",
    "\n",
    "nn = torchani.ANIModel([H_network, C_network, N_network, O_network])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce874e7b",
   "metadata": {},
   "source": [
    "Initialize the weights and biases.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Pytorch default initialization for the weights and biases in linear layers\n",
    "  is Kaiming uniform. See: `TORCH.NN.MODULES.LINEAR`_\n",
    "  We initialize the weights similarly but from the normal distribution.\n",
    "  The biases were initialized to zero.</p></div>\n",
    "\n",
    "  https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5071d8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANIModel(\n",
       "  (0): Sequential(\n",
       "    (0): Linear(in_features=392, out_features=160, bias=True)\n",
       "    (1): CELU(alpha=0.1)\n",
       "    (2): Linear(in_features=160, out_features=128, bias=True)\n",
       "    (3): CELU(alpha=0.1)\n",
       "    (4): Linear(in_features=128, out_features=96, bias=True)\n",
       "    (5): CELU(alpha=0.1)\n",
       "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=392, out_features=144, bias=True)\n",
       "    (1): CELU(alpha=0.1)\n",
       "    (2): Linear(in_features=144, out_features=112, bias=True)\n",
       "    (3): CELU(alpha=0.1)\n",
       "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
       "    (5): CELU(alpha=0.1)\n",
       "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=392, out_features=128, bias=True)\n",
       "    (1): CELU(alpha=0.1)\n",
       "    (2): Linear(in_features=128, out_features=112, bias=True)\n",
       "    (3): CELU(alpha=0.1)\n",
       "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
       "    (5): CELU(alpha=0.1)\n",
       "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Linear(in_features=392, out_features=128, bias=True)\n",
       "    (1): CELU(alpha=0.1)\n",
       "    (2): Linear(in_features=128, out_features=112, bias=True)\n",
       "    (3): CELU(alpha=0.1)\n",
       "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
       "    (5): CELU(alpha=0.1)\n",
       "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_params(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight, a=1.0)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "nn.apply(init_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd0601",
   "metadata": {},
   "source": [
    "Let's now create a pipeline of AEV Computer --> Neural Networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1341cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): AEVComputer()\n",
      "  (1): ANIModel(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=392, out_features=160, bias=True)\n",
      "      (1): CELU(alpha=0.1)\n",
      "      (2): Linear(in_features=160, out_features=128, bias=True)\n",
      "      (3): CELU(alpha=0.1)\n",
      "      (4): Linear(in_features=128, out_features=96, bias=True)\n",
      "      (5): CELU(alpha=0.1)\n",
      "      (6): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=392, out_features=144, bias=True)\n",
      "      (1): CELU(alpha=0.1)\n",
      "      (2): Linear(in_features=144, out_features=112, bias=True)\n",
      "      (3): CELU(alpha=0.1)\n",
      "      (4): Linear(in_features=112, out_features=96, bias=True)\n",
      "      (5): CELU(alpha=0.1)\n",
      "      (6): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=392, out_features=128, bias=True)\n",
      "      (1): CELU(alpha=0.1)\n",
      "      (2): Linear(in_features=128, out_features=112, bias=True)\n",
      "      (3): CELU(alpha=0.1)\n",
      "      (4): Linear(in_features=112, out_features=96, bias=True)\n",
      "      (5): CELU(alpha=0.1)\n",
      "      (6): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=392, out_features=128, bias=True)\n",
      "      (1): CELU(alpha=0.1)\n",
      "      (2): Linear(in_features=128, out_features=112, bias=True)\n",
      "      (3): CELU(alpha=0.1)\n",
      "      (4): Linear(in_features=112, out_features=96, bias=True)\n",
      "      (5): CELU(alpha=0.1)\n",
      "      (6): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torchani.nn.Sequential(aev_computer, nn).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa4350",
   "metadata": {},
   "source": [
    "Now let's setup the optimizers. NeuroChem uses Adam with decoupled weight decay\n",
    "to updates the weights and Stochastic Gradient Descent (SGD) to update the biases.\n",
    "Moreover, we need to specify different weight decay rate for different layes.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The weight decay in `inputtrain.ipt`_ is named \"l2\", but it is actually not\n",
    "  L2 regularization. The confusion between L2 and weight decay is a common\n",
    "  mistake in deep learning.  See: `Decoupled Weight Decay Regularization`_\n",
    "  Also note that the weight decay only applies to weight in the training\n",
    "  of ANI models, not bias.</p></div>\n",
    "\n",
    "  https://arxiv.org/abs/1711.05101\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1395f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdamW = torch.optim.AdamW([\n",
    "    #H networks\n",
    "    {'params': [H_network[0].weight]},\n",
    "    {'params': [H_network[2].weight], 'weight_decay': 0.00001},\n",
    "    {'params': [H_network[4].weight], 'weight_decay': 0.000001},\n",
    "    {'params': [H_network[6].weight]},\n",
    "    # C networks\n",
    "    {'params': [C_network[0].weight]},\n",
    "    {'params': [C_network[2].weight], 'weight_decay': 0.00001},\n",
    "    {'params': [C_network[4].weight], 'weight_decay': 0.000001},\n",
    "    {'params': [C_network[6].weight]},\n",
    "    # N networks\n",
    "    {'params': [N_network[0].weight]},\n",
    "    {'params': [N_network[2].weight], 'weight_decay': 0.00001},\n",
    "    {'params': [N_network[4].weight], 'weight_decay': 0.000001},\n",
    "    {'params': [N_network[6].weight]},\n",
    "    # O networks\n",
    "    {'params': [O_network[0].weight]},\n",
    "    {'params': [O_network[2].weight], 'weight_decay': 0.00001},\n",
    "    {'params': [O_network[4].weight], 'weight_decay': 0.000001},\n",
    "    {'params': [O_network[6].weight]},\n",
    "])\n",
    "\n",
    "SGD = torch.optim.SGD([\n",
    "    # H networks\n",
    "    {'params': [H_network[0].bias]},\n",
    "    {'params': [H_network[2].bias]},\n",
    "    {'params': [H_network[4].bias]},\n",
    "    {'params': [H_network[6].bias]},\n",
    "    # C networks\n",
    "    {'params': [C_network[0].bias]},\n",
    "    {'params': [C_network[2].bias]},\n",
    "    {'params': [C_network[4].bias]},\n",
    "    {'params': [C_network[6].bias]},\n",
    "    # N networks\n",
    "    {'params': [N_network[0].bias]},\n",
    "    {'params': [N_network[2].bias]},\n",
    "    {'params': [N_network[4].bias]},\n",
    "    {'params': [N_network[6].bias]},\n",
    "    # O networks\n",
    "    {'params': [O_network[0].bias]},\n",
    "    {'params': [O_network[2].bias]},\n",
    "    {'params': [O_network[4].bias]},\n",
    "    {'params': [O_network[6].bias]},\n",
    "], lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0569a",
   "metadata": {},
   "source": [
    "Setting up a learning rate scheduler to do learning rate decay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902ff127",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdamW_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(AdamW, factor=0.5, patience=100, threshold=0)\n",
    "SGD_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(SGD, factor=0.5, patience=100, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ab28d",
   "metadata": {},
   "source": [
    "Train the model by minimizing the MSE loss, until validation RMSE no longer\n",
    "improves during a certain number of steps, decay the learning rate and repeat\n",
    "the same process, stop until the learning rate is smaller than a threshold.\n",
    "\n",
    "We first read the checkpoint files to restart training. We use `latest.pt`\n",
    "to store current training state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9cbb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_checkpoint = 'latest.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59833d",
   "metadata": {},
   "source": [
    "Resume training from previously saved checkpoints:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8556a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(latest_checkpoint):\n",
    "    checkpoint = torch.load(latest_checkpoint)\n",
    "    nn.load_state_dict(checkpoint['nn'])\n",
    "    AdamW.load_state_dict(checkpoint['AdamW'])\n",
    "    SGD.load_state_dict(checkpoint['SGD'])\n",
    "    AdamW_scheduler.load_state_dict(checkpoint['AdamW_scheduler'])\n",
    "    SGD_scheduler.load_state_dict(checkpoint['SGD_scheduler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b3bd4",
   "metadata": {},
   "source": [
    "During training, we need to validate on validation set and if validation error\n",
    "is better than the best, then save the new best model to a checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3efe83a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    # run validation\n",
    "    mse_sum = torch.nn.MSELoss(reduction='sum')\n",
    "    total_mse = 0.0\n",
    "    count = 0\n",
    "    for properties in validation:\n",
    "        species = properties['species'].to(device)\n",
    "        coordinates = properties['coordinates'].to(device).float()\n",
    "        true_energies = properties['energies'].to(device).float()\n",
    "        _, predicted_energies = model((species, coordinates))\n",
    "        total_mse += mse_sum(predicted_energies, true_energies).item()\n",
    "        count += predicted_energies.shape[0]\n",
    "    return hartree2kcalmol(math.sqrt(total_mse / count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc560692",
   "metadata": {},
   "source": [
    "We will also use TensorBoard to visualize our training process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bd8d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = torch.utils.tensorboard.SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e4a4b",
   "metadata": {},
   "source": [
    "Finally, we come to the training loop.\n",
    "\n",
    "In this tutorial, we are setting the maximum epoch to a very small number,\n",
    "only to make this demo terminate fast. For serious training, this should be\n",
    "set to a much larger value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d050a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training starting from epoch 1\n",
      "RMSE: 72.43142181504693 at epoch 1\n",
      "RMSE: 593.1103116677587 at epoch 2\n",
      "RMSE: 229.12755548778242 at epoch 3\n",
      "RMSE: 117.61176156606291 at epoch 4\n",
      "RMSE: 177.42319377781914 at epoch 5\n",
      "RMSE: 91.35677939132087 at epoch 6\n",
      "RMSE: 63.513128178860335 at epoch 7\n",
      "RMSE: 88.71436796938939 at epoch 8\n",
      "RMSE: 16.157337220066097 at epoch 9\n",
      "RMSE: 53.318074678666235 at epoch 10\n",
      "RMSE: 29.62238073911466 at epoch 11\n",
      "RMSE: 27.434343439458672 at epoch 12\n",
      "RMSE: 25.813119971710503 at epoch 13\n",
      "RMSE: 19.2751108540776 at epoch 14\n",
      "RMSE: 15.002685064729263 at epoch 15\n",
      "RMSE: 17.62991501344075 at epoch 16\n",
      "RMSE: 11.409474038987868 at epoch 17\n",
      "RMSE: 12.01629082130903 at epoch 18\n",
      "RMSE: 11.712009229671056 at epoch 19\n",
      "RMSE: 10.258979721052835 at epoch 20\n",
      "RMSE: 9.750394830188556 at epoch 21\n",
      "RMSE: 9.345946586906745 at epoch 22\n",
      "RMSE: 9.358737870632712 at epoch 23\n",
      "RMSE: 8.574887659962538 at epoch 24\n",
      "RMSE: 8.396436518184176 at epoch 25\n",
      "RMSE: 8.278717383217788 at epoch 26\n",
      "RMSE: 7.931588623499198 at epoch 27\n",
      "RMSE: 7.715476813435885 at epoch 28\n",
      "RMSE: 7.499308156208145 at epoch 29\n",
      "RMSE: 7.30411083097346 at epoch 30\n",
      "RMSE: 7.112886393788833 at epoch 31\n",
      "RMSE: 6.911151295714259 at epoch 32\n",
      "RMSE: 6.747414116675187 at epoch 33\n",
      "RMSE: 6.5584920939987335 at epoch 34\n",
      "RMSE: 6.39167324123864 at epoch 35\n",
      "RMSE: 6.238775326525316 at epoch 36\n",
      "RMSE: 6.072129936467608 at epoch 37\n",
      "RMSE: 5.925924146921599 at epoch 38\n",
      "RMSE: 5.780544775211147 at epoch 39\n",
      "RMSE: 5.6376499469209 at epoch 40\n",
      "RMSE: 5.497872430506817 at epoch 41\n",
      "RMSE: 5.341895625919198 at epoch 42\n",
      "RMSE: 5.140337986523287 at epoch 43\n",
      "RMSE: 5.015069967130681 at epoch 44\n",
      "RMSE: 4.897297877986451 at epoch 45\n",
      "RMSE: 4.771320482748234 at epoch 46\n",
      "RMSE: 4.6755118001947995 at epoch 47\n",
      "RMSE: 4.593237280857534 at epoch 48\n",
      "RMSE: 4.512936712277764 at epoch 49\n",
      "RMSE: 4.442422319265195 at epoch 50\n",
      "RMSE: 4.384556514629963 at epoch 51\n",
      "RMSE: 4.332094544287492 at epoch 52\n",
      "RMSE: 4.2852266411639 at epoch 53\n",
      "RMSE: 4.244170617383239 at epoch 54\n",
      "RMSE: 4.206779302703512 at epoch 55\n",
      "RMSE: 4.173288877478785 at epoch 56\n",
      "RMSE: 4.143241255274841 at epoch 57\n",
      "RMSE: 4.115276362007305 at epoch 58\n",
      "RMSE: 4.08905379042695 at epoch 59\n",
      "RMSE: 4.064564321956007 at epoch 60\n",
      "RMSE: 4.0413429217920145 at epoch 61\n",
      "RMSE: 4.018840441959385 at epoch 62\n",
      "RMSE: 3.9970856751134587 at epoch 63\n",
      "RMSE: 3.9760179616394247 at epoch 64\n",
      "RMSE: 3.9552645473865606 at epoch 65\n",
      "RMSE: 3.934789500926858 at epoch 66\n",
      "RMSE: 3.914639693608803 at epoch 67\n",
      "RMSE: 3.8947080549331488 at epoch 68\n",
      "RMSE: 3.874875094320578 at epoch 69\n",
      "RMSE: 3.8551634738375107 at epoch 70\n",
      "RMSE: 3.8356193285788174 at epoch 71\n",
      "RMSE: 3.8161731590847374 at epoch 72\n",
      "RMSE: 3.7967890877197865 at epoch 73\n",
      "RMSE: 3.777515173036688 at epoch 74\n",
      "RMSE: 3.758377323013136 at epoch 75\n",
      "RMSE: 3.739363824120129 at epoch 76\n",
      "RMSE: 3.7204738448078496 at epoch 77\n",
      "RMSE: 3.701718265650059 at epoch 78\n",
      "RMSE: 3.683083098056161 at epoch 79\n",
      "RMSE: 3.664548496402158 at epoch 80\n",
      "RMSE: 3.6461405803933635 at epoch 81\n",
      "RMSE: 3.6278594064954497 at epoch 82\n",
      "RMSE: 3.6096873340089037 at epoch 83\n",
      "RMSE: 3.5916358513302145 at epoch 84\n",
      "RMSE: 3.5736980443184057 at epoch 85\n",
      "RMSE: 3.5558735324619986 at epoch 86\n",
      "RMSE: 3.5381540470572133 at epoch 87\n",
      "RMSE: 3.520531528821981 at epoch 88\n",
      "RMSE: 3.5030101553391493 at epoch 89\n",
      "RMSE: 3.4855861913213824 at epoch 90\n",
      "RMSE: 3.4682544473247403 at epoch 91\n",
      "RMSE: 3.4510119834437956 at epoch 92\n",
      "RMSE: 3.433855002516904 at epoch 93\n",
      "RMSE: 3.4167772393778537 at epoch 94\n",
      "RMSE: 3.399769900076616 at epoch 95\n",
      "RMSE: 3.3828272211146944 at epoch 96\n",
      "RMSE: 3.3659511877149932 at epoch 97\n",
      "RMSE: 3.3491223270566515 at epoch 98\n",
      "RMSE: 3.3323442069842164 at epoch 99\n"
     ]
    }
   ],
   "source": [
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "print(\"training starting from epoch\", AdamW_scheduler.last_epoch + 1)\n",
    "max_epochs = 100\n",
    "early_stopping_learning_rate = 1.0E-7\n",
    "best_model_checkpoint = 'best.pt'\n",
    "\n",
    "for _ in range(AdamW_scheduler.last_epoch + 1, max_epochs):\n",
    "    rmse = validate()\n",
    "    #rmse =  0\n",
    "    print('RMSE:', rmse, 'at epoch', AdamW_scheduler.last_epoch + 1)\n",
    "\n",
    "    learning_rate = AdamW.param_groups[0]['lr']\n",
    "\n",
    "    if learning_rate < early_stopping_learning_rate:\n",
    "        break\n",
    "\n",
    "    # checkpoint\n",
    "    if AdamW_scheduler.is_better(rmse, AdamW_scheduler.best):\n",
    "        torch.save(nn.state_dict(), best_model_checkpoint)\n",
    "\n",
    "    AdamW_scheduler.step(rmse)\n",
    "    SGD_scheduler.step(rmse)\n",
    "\n",
    "    tensorboard.add_scalar('validation_rmse', rmse, AdamW_scheduler.last_epoch)\n",
    "    tensorboard.add_scalar('best_validation_rmse', AdamW_scheduler.best, AdamW_scheduler.last_epoch)\n",
    "    tensorboard.add_scalar('learning_rate', learning_rate, AdamW_scheduler.last_epoch)\n",
    "\n",
    "    for i, properties in tqdm.tqdm(\n",
    "        enumerate(training),\n",
    "        total=len(training),\n",
    "        desc=\"epoch {}\".format(AdamW_scheduler.last_epoch),\n",
    "        disable = True\n",
    "    ):\n",
    "        species = properties['species'].to(device)\n",
    "        coordinates = properties['coordinates'].to(device).float()\n",
    "        true_energies = properties['energies'].to(device).float()\n",
    "        num_atoms = (species >= 0).sum(dim=1, dtype=true_energies.dtype)\n",
    "        _, predicted_energies = model((species, coordinates))\n",
    "\n",
    "        loss = (mse(predicted_energies, true_energies) / num_atoms.sqrt()).mean()\n",
    "\n",
    "        AdamW.zero_grad()\n",
    "        SGD.zero_grad()\n",
    "        loss.backward()\n",
    "        AdamW.step()\n",
    "        SGD.step()\n",
    "\n",
    "        # write current batch loss to TensorBoard\n",
    "        tensorboard.add_scalar('batch_loss', loss, AdamW_scheduler.last_epoch * len(training) + i)\n",
    "\n",
    "    torch.save({\n",
    "        'nn': nn.state_dict(),\n",
    "        'AdamW': AdamW.state_dict(),\n",
    "        'SGD': SGD.state_dict(),\n",
    "        'AdamW_scheduler': AdamW_scheduler.state_dict(),\n",
    "        'SGD_scheduler': SGD_scheduler.state_dict(),\n",
    "    }, latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b83b6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model with torch.jit\n",
    "compiled_model = torch.jit.script(model)\n",
    "torch.jit.save(compiled_model, 'compiled_model.pt')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56d04215",
   "metadata": {},
   "source": [
    "# Saving the model with torch.save()\n",
    "torch.save(model, 'ani03_erf.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b5ca86",
   "metadata": {},
   "source": [
    "## Loading model and ploting C-O bond distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3add1c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=Sequential\n",
       "  (0): RecursiveScriptModule(original_name=AEVComputer)\n",
       "  (1): RecursiveScriptModule(\n",
       "    original_name=ANIModel\n",
       "    (0): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(original_name=Linear)\n",
       "      (1): RecursiveScriptModule(original_name=CELU)\n",
       "      (2): RecursiveScriptModule(original_name=Linear)\n",
       "      (3): RecursiveScriptModule(original_name=CELU)\n",
       "      (4): RecursiveScriptModule(original_name=Linear)\n",
       "      (5): RecursiveScriptModule(original_name=CELU)\n",
       "      (6): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "    (1): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(original_name=Linear)\n",
       "      (1): RecursiveScriptModule(original_name=CELU)\n",
       "      (2): RecursiveScriptModule(original_name=Linear)\n",
       "      (3): RecursiveScriptModule(original_name=CELU)\n",
       "      (4): RecursiveScriptModule(original_name=Linear)\n",
       "      (5): RecursiveScriptModule(original_name=CELU)\n",
       "      (6): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "    (2): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(original_name=Linear)\n",
       "      (1): RecursiveScriptModule(original_name=CELU)\n",
       "      (2): RecursiveScriptModule(original_name=Linear)\n",
       "      (3): RecursiveScriptModule(original_name=CELU)\n",
       "      (4): RecursiveScriptModule(original_name=Linear)\n",
       "      (5): RecursiveScriptModule(original_name=CELU)\n",
       "      (6): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "    (3): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(original_name=Linear)\n",
       "      (1): RecursiveScriptModule(original_name=CELU)\n",
       "      (2): RecursiveScriptModule(original_name=Linear)\n",
       "      (3): RecursiveScriptModule(original_name=CELU)\n",
       "      (4): RecursiveScriptModule(original_name=Linear)\n",
       "      (5): RecursiveScriptModule(original_name=CELU)\n",
       "      (6): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.jit.load('compiled_model.pt')\n",
    "#model = torch.load('./ani03_erf.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [i/100 for i in range(1,300)]\n",
    "energyData = []\n",
    "\n",
    "for i in D:\n",
    "    coordinates = torch.tensor([[[0.0, 0.0, 0.0],\n",
    "                             [0.0, 0.0, i ]]],requires_grad=True, device=device)\n",
    "    # In periodic table, C = 6 and O = 8, species_order = ['H', 'C', 'N', 'O']\n",
    "    species = torch.tensor([[1,3]], device=device)\n",
    "\n",
    "    energy = model((species, coordinates)).energies\n",
    "    energyData.append(energy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53dff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(D,energyData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
